{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4embtkV0pNxM"
   },
   "source": [
    "# Lab 11\n",
    "\n",
    "Convolutional neural networks\n",
    "=============\n",
    "## Submitted to: Prof. Sweetlin Hemlatha\n",
    "## Submitted by: Prateek Singh (15BCE1091)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "tm2CQN_Cpwj0"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 186058,
     "status": "ok",
     "timestamp": 1444485672507,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "2a0a5e044bb03b66",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "EYRJ4ICW6-da",
    "outputId": "0d0f85df-155f-4a89-8e7e-ee32df36ec8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified ./notMNIST_large.tar.gz\n",
      "Found and verified ./notMNIST_small.tar.gz\n"
     ]
    }
   ],
   "source": [
    "url = 'https://commondatastorage.googleapis.com/books1000/'\n",
    "last_percent_reported = None\n",
    "data_root = '.' # Change me to store data elsewhere\n",
    "\n",
    "def download_progress_hook(count, blockSize, totalSize):\n",
    "  global last_percent_reported\n",
    "  percent = int(count * blockSize * 100 / totalSize)\n",
    "\n",
    "  if last_percent_reported != percent:\n",
    "    if percent % 5 == 0:\n",
    "      sys.stdout.write(\"%s%%\" % percent)\n",
    "      sys.stdout.flush()\n",
    "    else:\n",
    "      sys.stdout.write(\".\")\n",
    "      sys.stdout.flush()\n",
    "      \n",
    "    last_percent_reported = percent\n",
    "        \n",
    "def maybe_download(filename, expected_bytes, force=False):\n",
    "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "  dest_filename = os.path.join(data_root, filename)\n",
    "  if force or not os.path.exists(dest_filename):\n",
    "    print('Attempting to download:', filename) \n",
    "    filename, _ = urlretrieve(url + filename, dest_filename, reporthook=download_progress_hook)\n",
    "    print('\\nDownload Complete!')\n",
    "  statinfo = os.stat(dest_filename)\n",
    "  if statinfo.st_size == expected_bytes:\n",
    "    print('Found and verified', dest_filename)\n",
    "  else:\n",
    "    raise Exception(\n",
    "      'Failed to verify ' + dest_filename + '. Can you get to it with a browser?')\n",
    "  return dest_filename\n",
    "\n",
    "train_filename = maybe_download('notMNIST_large.tar.gz', 247336696)\n",
    "test_filename = maybe_download('notMNIST_small.tar.gz', 8458043)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cC3p0oEyF8QT"
   },
   "source": [
    "Extract the dataset from the compressed .tar.gz file.\n",
    "This would give us a set of directories, labeled A through J."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 186055,
     "status": "ok",
     "timestamp": 1444485672525,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "2a0a5e044bb03b66",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "H8CBE-WZ8nmj",
    "outputId": "ef6c790c-2513-4b09-962e-27c79390c762"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./notMNIST_large already present - Skipping extraction of ./notMNIST_large.tar.gz.\n",
      "['./notMNIST_large/A', './notMNIST_large/B', './notMNIST_large/C', './notMNIST_large/D', './notMNIST_large/E', './notMNIST_large/F', './notMNIST_large/G', './notMNIST_large/H', './notMNIST_large/I', './notMNIST_large/J']\n",
      "./notMNIST_small already present - Skipping extraction of ./notMNIST_small.tar.gz.\n",
      "['./notMNIST_small/A', './notMNIST_small/B', './notMNIST_small/C', './notMNIST_small/D', './notMNIST_small/E', './notMNIST_small/F', './notMNIST_small/G', './notMNIST_small/H', './notMNIST_small/I', './notMNIST_small/J']\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "np.random.seed(133)\n",
    "\n",
    "def maybe_extract(filename, force=False):\n",
    "  root = os.path.splitext(os.path.splitext(filename)[0])[0]  # remove .tar.gz\n",
    "  if os.path.isdir(root) and not force:\n",
    "    # You may override by setting force=True.\n",
    "    print('%s already present - Skipping extraction of %s.' % (root, filename))\n",
    "  else:\n",
    "    print('Extracting data for %s. This may take a while. Please wait.' % root)\n",
    "    tar = tarfile.open(filename)\n",
    "    sys.stdout.flush()\n",
    "    tar.extractall(data_root)\n",
    "    tar.close()\n",
    "  data_folders = [\n",
    "    os.path.join(root, d) for d in sorted(os.listdir(root))\n",
    "    if os.path.isdir(os.path.join(root, d))]\n",
    "  if len(data_folders) != num_classes:\n",
    "    raise Exception(\n",
    "      'Expected %d folders, one per class. Found %d instead.' % (\n",
    "        num_classes, len(data_folders)))\n",
    "  print(data_folders)\n",
    "  return data_folders\n",
    "  \n",
    "train_folders = maybe_extract(train_filename)\n",
    "test_folders = maybe_extract(test_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4riXK3IoHgx6"
   },
   "source": [
    "Looking at the dataset to ensure it's is sensible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABmElEQVR4nG2SPWiTURiFn/e9tx+1KLTiH/5gURDBwRKXLgpmKbUu4uJQEEodKuIWcHFwyGahDooICnYSh3YSpMWhWIs/ONRO4tCqbSmKEoJKIpjjoEm/5Mu7XQ7PPef9gXoZPSvSfQJtKjKq3/p6GM9qRvJSiyXdaIc6g9KZe1rpxtqIU1pkQLqSRZ2+iq7Cc73akkGdW1rdB8PSuVbU2LumCTroWdJMa95IQT+O45FrquabUWPbkqYwjD0bmmw2DVyQhgjgjOvX0fTHZjzTm4BBIFfWBDENnmz0F3isTwdTqPNQn3f9c3JOS4XNSM6Rb7r5/22EWb3fHESkqHIfSYwxxtjJRWmk7mrsXNaDdPwXmkswiOB/zvcSx7pqdZdKlVP5pyYMk78+sf59a60Bemn/jidnvQYEhqTBdNuBS6r0EwBjWgudBG9UoPuD7uLg5H5qLD0SCFxX6RBG4LY+bm8etdO7oSIRDnxRsXWDzh0t7wYKKh/LirmqLkPXOz1qd1LTepswIuWzd+wMSMPMa74je6lGsqC5v7lQlCHDd6K3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABgElEQVR4nHWTzUtUYRSHn3Pe904TaiOj48JwUSIxrmSCodWACzdC0C5rFbjy33AX/QW2rJiNBQluZEBm08IiEMkPNJcuGmGCyxTJ/TgtHCune5/tw+E9v3POK8Y1ku7J0U77NBFJQRI9ejWcXhoJRsqT9yaIP62t/9QUIntL8G+tm3nWTmy/jkJk77jp/+AEoLFv4Tz6f6Wod1T27OstlEEsjZPg/DnTSxkSIKbVo54jwQvkSEdjiIOMKIgLGPlo3yYvoxTdX7xDuL1lvx5nRUFmX4R2soDihbHqeHzVRrE0NVOb1Z3meqgpmCUXV0RmZmbbT4cRcSCR33hUjvpzLxTLlanag+qNDy/fhy7JeBOqq107fNhvqCB9VJ3zToTRptlyVk5QD03rNTIlBMx1rZkz21h295jPkaaElHKkpFqikyO93a/RypqtekewYd/rgwfmvYIwvWm2krnPicXXP6zzBLl21EihOFa5c1c5frPW0VQGvgNp7+zLbvvzhWjCb4lppnNHok9sAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABqElEQVR4nHWSTUiUYRSFn3vvO/04YUWLCiLbaIEbibGCEkaDwMCEqJVEKxe1a2Gr2gm1bFEEFUS7oV3RMhgTCbQf+9lMGNQiKKlJp2hI7Xtvi8+0GWfO9uHce+7lCIAS6Rjo7dzWYks/Pj4tTP1RIiAp67ucn5+YLJUXtuw52Ldr5mqhqpHUt+O+fxrOIgBg/a/8dQ4DMPa983stiAUzsxAEGfXqCQyEtpLfQMKyDyQYl7xyGAUe+uN1ovwnMR55MQCnfOFQumBVRj7xfqDoD9BahpB95rfhyC8/XW8EoXuwCy56eStSD1OFbqYrjYCKx9BOKS5/o0YR0J3Mrsmz4s7ys9lK1Joi0Cob8WbwC9tpkAcEdIbdxAaTxU31JbnWRkaXJJL/7T1rbxFai2MnsUm/RaiHxjlfGoAhL3fUf17ZPO0FYP243yXURJIMV/xbJyi57z6C2WpNLHDWfQgD5VjFRy0tmJoFgQsxOZ+mNLpe+JvBzMrUA2P+oTctH2jccGakffbJ1Pu5xU1t+4/u/Xz95pwl/8IpmZ5rz78uuiflt3eOZxED+AtF8om5rcUYWgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABQElEQVR4nHXTTytEURzG8e/vnDtCM9TUDCkpoVHegCTFQl6AHUVeBDKNsrS1kdWUZiNvwE7+JYtZIE2jiaQkRmR3zb0/ixGTuefZfnr6Lc5zRPmL//xwc3F2+4UhBJCaPTxIhIC0tCfTg71Iea9QEgkBfM0S++1KembrSf1CP7aOOdq8nwgIrXMVfVtApKkp1grxbdU1zH8EEE9YV13CRiCIJa/VIQwRUSV7n1yJRkL7uMt0JhpR9ukZdeLdJRMORD6vGHE1De8knU3eSLkQDIELlTgvDpSQFO/OZnyEivNmd4ZzBxrmW6pH0WiC5CyHxUgUw/Kwvxn12FjLomoO0zwTTzCrvu7UZ9IwMANgJ0+1tmFpGhgdY9mS6vE4VsAzTNUSIUCsrbOrbyDGaz5/pDYApPE7aPWxXDy5/kBMAPANjPR3mPPvKMQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAo0lEQVR4nM2SsQ3CQAxFnxMXiBQoc7ADYhi2YgB6eqoMQMECrIAok7tPgYI4JYYSful/tk/PHwXqdcRzdd03mYlyc4ZeJ3zqAeCGBaaSCzEM851VMPFnphtGraKmkYkLkVLYuVq376b8drHnKBO5RJAX3aZ+vvZUd9u2sC2RXjsT9wCfG2BWFsfPuwCJWf0d+O9XCdL3OWCWglCTlwcL4MDguwc6nFR5HSiBQQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAe0lEQVR4nM2QsQ2DUAxEn8EFY7AGG2S6jBelZYCIAgFKlPhSRYgvnBbcPp/PdybSWRyW6/6CTYQelkkd8EiwA+/Mt8r/OQY6UJdRFCv8ZFEcvNsqVc+3pwkwwWu7H8390lcBWNjQlp4x63dW4x9PTGXxWqFIpKcr/nTwC2xVKYylBKO/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABzklEQVR4nG2RT4jMYRjHP+/zvLOGZjfGbNOuE5LJnzjYpZSNhD0ItTlwcaVNRNKmKDcHJTcOLmprldi0cti2WMtmE0lSmxtrZG2MmWln5vd7HH6b+c3Ofm5vn573+37fxwE4F5I9cnhTOuUrxa8TT0ZLTgLARW7LQF/55atPP6urO3fuWfftzu1fGgAgJG/Y7Lk2HAC4nnGbOY5Ern3MHqVx4lVVvXdwumJXEXC0Pbf74BfmwKlybN7Oowh3bbIVJYZLcNnKO4D9Zr14GnAkJ+wxMGLDUXgc5ZTN5Oj+bScaL41oPZpLctHyGVyzBJBu3s0uJZwKfiOfTcJmaQFIB/nm9yzgU5TikRqP94Zi9XPQMFlckapLCW9uLUYhUiqIz7d31KVRmCtF6yhv6woZslFdomeCfivJe7avjMckIjyr8DL2N70v1qVWjZgng4MX9rD5bx0tkxbASav1LF4ZSpeZgTyz14uWjQjDVjMc66dtUPD1XKfKgP2wEJTN0/Z0Dc55VVX1Cnrd7l2wCiB0PrA/17L/2y7v+2iDnLGyA8Rs76UDwdSbt98Ly9Ibdu3OfLgyUjt7q+oAhJC1h3pz2ZRQKXwZH5qqtVQO9s/9A4qip8sk26hFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAdUlEQVR4nO2PMQ6DQAwExznfByJR3A94HXyEJgWvRKKhwxymSKQUPvGBZMsdadZm94lMSGby/RH7b34FKgjpDH0yAQWn1obRQYXSd0c0LgURpx7S2HNNqOV5fFpgeX0NpmBsDYiBAkj0yucVcI+T75Nv8ofABeaKHpW7ewzfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAFklEQVR4nGP8z4AbMOGRG5UclRxhkgCD/gE3CChK/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAxklEQVR4nO3OMUpDQRSF4X/uTMTUGhCbFAaChSA2CnYuI/CwSZkNZBk2qVII2UAKd6AgwdoqYCJYpDU8EOKbOSlsHoTZQPCU9zv3ch2ZCLAc8o97hyEAVQZdbktA6APjbENS2B0fSirt8zfG05237AzS3KYNfC/5OjuzNFC0Ea2lqvUNuOD/EgJwX0lTg86LtBme1I9ePUrpIeCcXFHcNuNsNv8qf3zzuH1x3WHxNHkDhyXoXt6dt48aBxA35erj9fn9G5+0BWJ5QU0fOkCMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for folders in train_folders:\n",
    "    a = os.listdir(folders)\n",
    "    display(Image(filename = folders + '/' + a[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PBdkjESPK8tw"
   },
   "source": [
    "Loading the data in a more manageable format\n",
    "\n",
    "We'll convert the entire dataset into a 3D array (image index, x, y) of floating point values, normalized to have approximately zero mean and standard deviation ~0.5 to make training easier down the road. \n",
    "\n",
    "A few images might not be readable, we'll just skip them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 30
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 399874,
     "status": "ok",
     "timestamp": 1444485886378,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "2a0a5e044bb03b66",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "h7q0XhG3MJdf",
    "outputId": "92c391bb-86ff-431d-9ada-315568a19e59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./notMNIST_large/A.pickle already present - Skipping pickling.\n",
      "./notMNIST_large/B.pickle already present - Skipping pickling.\n",
      "./notMNIST_large/C.pickle already present - Skipping pickling.\n",
      "./notMNIST_large/D.pickle already present - Skipping pickling.\n",
      "./notMNIST_large/E.pickle already present - Skipping pickling.\n",
      "./notMNIST_large/F.pickle already present - Skipping pickling.\n",
      "./notMNIST_large/G.pickle already present - Skipping pickling.\n",
      "./notMNIST_large/H.pickle already present - Skipping pickling.\n",
      "./notMNIST_large/I.pickle already present - Skipping pickling.\n",
      "./notMNIST_large/J.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/A.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/B.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/C.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/D.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/E.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/F.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/G.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/H.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/I.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/J.pickle already present - Skipping pickling.\n"
     ]
    }
   ],
   "source": [
    "image_size = 28  # Pixel width and height.\n",
    "pixel_depth = 255.0  # Number of levels per pixel.\n",
    "\n",
    "def load_letter(folder, min_num_images):\n",
    "  \"\"\"Load the data for a single letter label.\"\"\"\n",
    "  image_files = os.listdir(folder)\n",
    "  dataset = np.ndarray(shape=(len(image_files), image_size, image_size),\n",
    "                         dtype=np.float32)\n",
    "  print(folder)\n",
    "  num_images = 0\n",
    "  for image in image_files:\n",
    "    image_file = os.path.join(folder, image)\n",
    "    try:\n",
    "      image_data = (imageio.imread(image_file).astype(float) - \n",
    "                    pixel_depth / 2) / pixel_depth\n",
    "      if image_data.shape != (image_size, image_size):\n",
    "        raise Exception('Unexpected image shape: %s' % str(image_data.shape))\n",
    "      dataset[num_images, :, :] = image_data\n",
    "      num_images = num_images + 1\n",
    "    except (IOError, ValueError) as e:\n",
    "      print('Could not read:', image_file, ':', e, '- it\\'s ok, skipping.')\n",
    "    \n",
    "  dataset = dataset[0:num_images, :, :]\n",
    "  if num_images < min_num_images:\n",
    "    raise Exception('Many fewer images than expected: %d < %d' %\n",
    "                    (num_images, min_num_images))\n",
    "    \n",
    "  print('Full dataset tensor:', dataset.shape)\n",
    "  print('Mean:', np.mean(dataset))\n",
    "  print('Standard deviation:', np.std(dataset))\n",
    "  return dataset\n",
    "        \n",
    "def maybe_pickle(data_folders, min_num_images_per_class, force=False):\n",
    "  dataset_names = []\n",
    "  for folder in data_folders:\n",
    "    set_filename = folder + '.pickle'\n",
    "    dataset_names.append(set_filename)\n",
    "    if os.path.exists(set_filename) and not force:\n",
    "      # You may override by setting force=True.\n",
    "      print('%s already present - Skipping pickling.' % set_filename)\n",
    "    else:\n",
    "      print('Pickling %s.' % set_filename)\n",
    "      dataset = load_letter(folder, min_num_images_per_class)\n",
    "      try:\n",
    "        with open(set_filename, 'wb') as f:\n",
    "          pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "      except Exception as e:\n",
    "        print('Unable to save data to', set_filename, ':', e)\n",
    "  \n",
    "  return dataset_names\n",
    "\n",
    "train_datasets = maybe_pickle(train_folders, 45000)\n",
    "test_datasets = maybe_pickle(test_folders, 1800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vUdbskYE2d87"
   },
   "source": [
    "Verifying that the data still looks good. Displaying a sample of the labels and images from the ndarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./notMNIST_large/J']\n",
      "['./notMNIST_large/A', './notMNIST_large/B', './notMNIST_large/C', './notMNIST_large/D', './notMNIST_large/E', './notMNIST_large/F', './notMNIST_large/G', './notMNIST_large/H', './notMNIST_large/I', './notMNIST_large/J']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbf9b936a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "def disp_8_img(imgs, titles):\n",
    "  \"\"\"Display subplot with 8 images or less\"\"\"\n",
    "  for i, img in enumerate(imgs):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    plt.title(titles[i])\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "\n",
    "def disp_sample_pickles(data_folders):\n",
    "  folder = random.sample(data_folders, 1)\n",
    "  pickle_filename = ''.join(folder) + '.pickle'\n",
    "  print(folder)\n",
    "  print(data_folders)\n",
    "  try:\n",
    "    with open(pickle_filename, 'rb') as f:\n",
    "      dataset = pickle.load(f)\n",
    "  except Exception as e:\n",
    "    print('Unable to read data from', pickle_filename, ':', e)\n",
    "    return\n",
    "  # display\n",
    "  plt.suptitle(''.join(folder)[-1])\n",
    "  for i, img in enumerate(random.sample(list(dataset), 8)):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "    \n",
    "disp_sample_pickles(train_folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cYznx5jUwzoO"
   },
   "source": [
    "checking for the data to be balanced across classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in  ./notMNIST_large/A  :  52909\n",
      "Number of images in  ./notMNIST_large/B  :  52911\n",
      "Number of images in  ./notMNIST_large/C  :  52912\n",
      "Number of images in  ./notMNIST_large/D  :  52911\n",
      "Number of images in  ./notMNIST_large/E  :  52912\n",
      "Number of images in  ./notMNIST_large/F  :  52912\n",
      "Number of images in  ./notMNIST_large/G  :  52912\n",
      "Number of images in  ./notMNIST_large/H  :  52912\n",
      "Number of images in  ./notMNIST_large/I  :  52912\n",
      "Number of images in  ./notMNIST_large/J  :  52911\n",
      "Number of images in  ./notMNIST_small/A  :  1872\n",
      "Number of images in  ./notMNIST_small/B  :  1873\n",
      "Number of images in  ./notMNIST_small/C  :  1873\n",
      "Number of images in  ./notMNIST_small/D  :  1873\n",
      "Number of images in  ./notMNIST_small/E  :  1873\n",
      "Number of images in  ./notMNIST_small/F  :  1872\n",
      "Number of images in  ./notMNIST_small/G  :  1872\n",
      "Number of images in  ./notMNIST_small/H  :  1872\n",
      "Number of images in  ./notMNIST_small/I  :  1872\n",
      "Number of images in  ./notMNIST_small/J  :  1872\n"
     ]
    }
   ],
   "source": [
    "def disp_number_images(data_folders):\n",
    "  for folder in data_folders:\n",
    "    pickle_filename = ''.join(folder) + '.pickle'\n",
    "    try:\n",
    "      with open(pickle_filename, 'rb') as f:\n",
    "        dataset = pickle.load(f)\n",
    "    except Exception as e:\n",
    "      print('Unable to read data from', pickle_filename, ':', e)\n",
    "      return\n",
    "    print('Number of images in ', folder, ' : ', len(dataset))\n",
    "    \n",
    "disp_number_images(train_folders)\n",
    "disp_number_images(test_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 411281,
     "status": "ok",
     "timestamp": 1444485897869,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "2a0a5e044bb03b66",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "s3mWgZLpyuzq",
    "outputId": "8af66da6-902d-4719-bedc-7c9fb7ae7948"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./notMNIST_large/A.pickle', './notMNIST_large/B.pickle', './notMNIST_large/C.pickle', './notMNIST_large/D.pickle', './notMNIST_large/E.pickle', './notMNIST_large/F.pickle', './notMNIST_large/G.pickle', './notMNIST_large/H.pickle', './notMNIST_large/I.pickle', './notMNIST_large/J.pickle']\n",
      "['./notMNIST_small/A.pickle', './notMNIST_small/B.pickle', './notMNIST_small/C.pickle', './notMNIST_small/D.pickle', './notMNIST_small/E.pickle', './notMNIST_small/F.pickle', './notMNIST_small/G.pickle', './notMNIST_small/H.pickle', './notMNIST_small/I.pickle', './notMNIST_small/J.pickle']\n",
      "Training: (200000, 28, 28) (200000,)\n",
      "Validation: (10000, 28, 28) (10000,)\n",
      "Testing: (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "def make_arrays(nb_rows, img_size):\n",
    "  if nb_rows:\n",
    "    dataset = np.ndarray((nb_rows, img_size, img_size), dtype=np.float32)\n",
    "    labels = np.ndarray(nb_rows, dtype=np.int32)\n",
    "  else:\n",
    "    dataset, labels = None, None\n",
    "  return dataset, labels\n",
    "\n",
    "def merge_datasets(pickle_files, train_size, valid_size=0):\n",
    "  num_classes = len(pickle_files)\n",
    "  print(pickle_files)\n",
    "  valid_dataset, valid_labels = make_arrays(valid_size, image_size)\n",
    "  train_dataset, train_labels = make_arrays(train_size, image_size)\n",
    "  vsize_per_class = valid_size // num_classes\n",
    "  tsize_per_class = train_size // num_classes\n",
    "    \n",
    "  start_v, start_t = 0, 0\n",
    "  end_v, end_t = vsize_per_class, tsize_per_class\n",
    "  end_l = vsize_per_class+tsize_per_class\n",
    "  for label, pickle_file in enumerate(pickle_files):   \n",
    "    try:\n",
    "      with open(pickle_file, 'rb') as f:\n",
    "        letter_set = pickle.load(f)\n",
    "        # let's shuffle the letters to have random validation and training set\n",
    "        np.random.shuffle(letter_set)\n",
    "        if valid_dataset is not None:\n",
    "          valid_letter = letter_set[:vsize_per_class, :, :]\n",
    "          valid_dataset[start_v:end_v, :, :] = valid_letter\n",
    "          valid_labels[start_v:end_v] = label\n",
    "          start_v += vsize_per_class\n",
    "          end_v += vsize_per_class\n",
    "                    \n",
    "        train_letter = letter_set[vsize_per_class:end_l, :, :]\n",
    "        train_dataset[start_t:end_t, :, :] = train_letter\n",
    "        train_labels[start_t:end_t] = label\n",
    "        start_t += tsize_per_class\n",
    "        end_t += tsize_per_class\n",
    "    except Exception as e:\n",
    "      print('Unable to process data from', pickle_file, ':', e)\n",
    "      raise\n",
    "    \n",
    "  return valid_dataset, valid_labels, train_dataset, train_labels\n",
    "            \n",
    "            \n",
    "train_size = 200000\n",
    "valid_size = 10000\n",
    "test_size = 10000\n",
    "\n",
    "valid_dataset, valid_labels, train_dataset, train_labels = merge_datasets(\n",
    "  train_datasets, train_size, valid_size)\n",
    "_, _, test_dataset, test_labels = merge_datasets(test_datasets, test_size)\n",
    "\n",
    "print('Training:', train_dataset.shape, train_labels.shape)\n",
    "print('Validation:', valid_dataset.shape, valid_labels.shape)\n",
    "print('Testing:', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GPTCnjIcyuKN"
   },
   "source": [
    "Next, we'll randomize the data. It's important to have the labels well shuffled for the training and test distributions to match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "6WZ2l2tN2zOL"
   },
   "outputs": [],
   "source": [
    "def randomize(dataset, labels):\n",
    "  permutation = np.random.permutation(labels.shape[0])\n",
    "  shuffled_dataset = dataset[permutation,:,:]\n",
    "  shuffled_labels = labels[permutation]\n",
    "  return shuffled_dataset, shuffled_labels\n",
    "train_dataset, train_labels = randomize(train_dataset, train_labels)\n",
    "test_dataset, test_labels = randomize(test_dataset, test_labels)\n",
    "valid_dataset, valid_labels = randomize(valid_dataset, valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11948,
     "status": "ok",
     "timestamp": 1446658914837,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "016b1a51-0290-4b08-efdb-8c95ffc3cd01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a TensorFlow-friendly shape:\n",
    "- convolutions need the image data formatted as a cube (width by height by #channels)\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11952,
     "status": "ok",
     "timestamp": 1446658914857,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "650a208c-8359-4852-f4f5-8bf10e80ef6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28, 1) (200000, 10)\n",
      "Validation set (10000, 28, 28, 1) (10000, 10)\n",
      "Test set (10000, 28, 28, 1) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape(\n",
    "    (-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "AgQDIREv02p1"
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5rhgjmROXu2O"
   },
   "source": [
    "building a small network with two convolutional layers, followed by one fully connected layer. Convolutional networks are more expensive computationally, so we'll limit its depth and number of fully connected nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "IZYv70SvvOan"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "patch_size = 5\n",
    "depth = 16\n",
    "num_hidden = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "      [image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden, num_labels], stddev=0.1))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  \n",
    "  # Model.\n",
    "  def model(data):\n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer1_biases)\n",
    "    conv = tf.nn.conv2d(hidden, layer2_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer2_biases)\n",
    "    shape = hidden.get_shape().as_list()\n",
    "    reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "    \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 37
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 63292,
     "status": "ok",
     "timestamp": 1446658966251,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "noKFb2UovVFR",
    "outputId": "28941338-2ef9-4088-8bd1-44295661e628"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 3.252700\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 9.9%\n",
      "Minibatch loss at step 50: 1.850138\n",
      "Minibatch accuracy: 31.2%\n",
      "Validation accuracy: 48.7%\n",
      "Minibatch loss at step 100: 1.010035\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 64.9%\n",
      "Minibatch loss at step 150: 1.289849\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 72.0%\n",
      "Minibatch loss at step 200: 0.505446\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 75.6%\n",
      "Minibatch loss at step 250: 1.345587\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 69.6%\n",
      "Minibatch loss at step 300: 0.695081\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 350: 0.638521\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 400: 0.511915\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 450: 0.779062\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 500: 0.602857\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 550: 1.071783\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 600: 0.966325\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 650: 0.564390\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 700: 0.549062\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 750: 0.473424\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 800: 0.421251\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 850: 0.261832\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 900: 0.716957\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 82.2%\n",
      "Minibatch loss at step 950: 0.280484\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 82.5%\n",
      "Minibatch loss at step 1000: 0.360719\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 81.6%\n",
      "Test accuracy: 88.5%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 1001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 50 == 0):\n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KedKkn4EutIK"
   },
   "source": [
    "The convolutional model above uses convolutions with stride 2 to reduce the dimensionality. Replacing the strides by a max pooling operation (`nn.max_pool()`) of stride 2 and kernel size 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "patch_size = 5\n",
    "depth = 16\n",
    "num_hidden = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "      [image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden, num_labels], stddev=0.1))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  \n",
    "  # Model.\n",
    "  def model(data):\n",
    "    conv1 = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    bias1 = tf.nn.relu(conv1 + layer1_biases)\n",
    "    pool1 = tf.nn.max_pool(bias1, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    conv2 = tf.nn.conv2d(pool1, layer2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    bias2 = tf.nn.relu(conv2 + layer2_biases)\n",
    "    pool2 = tf.nn.max_pool(bias2, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    shape = pool2.get_shape().as_list()\n",
    "    reshape = tf.reshape(pool2, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "\n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "    \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 3.045946\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 50: 1.833991\n",
      "Minibatch accuracy: 31.2%\n",
      "Validation accuracy: 46.6%\n",
      "Minibatch loss at step 100: 1.044222\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 62.4%\n",
      "Minibatch loss at step 150: 1.086824\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 70.6%\n",
      "Minibatch loss at step 200: 0.626718\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 73.7%\n",
      "Minibatch loss at step 250: 1.310024\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 300: 0.477789\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 350: 0.495264\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 79.5%\n",
      "Minibatch loss at step 400: 0.597861\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 450: 0.637514\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 500: 0.441908\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 550: 0.707909\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 600: 1.103696\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 82.0%\n",
      "Minibatch loss at step 650: 0.399387\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 83.0%\n",
      "Minibatch loss at step 700: 0.450146\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 82.2%\n",
      "Minibatch loss at step 750: 0.412422\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 82.6%\n",
      "Minibatch loss at step 800: 0.354055\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 83.0%\n",
      "Minibatch loss at step 850: 0.240893\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 83.3%\n",
      "Minibatch loss at step 900: 0.460379\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 83.8%\n",
      "Minibatch loss at step 950: 0.301897\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 84.6%\n",
      "Minibatch loss at step 1000: 0.424297\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 83.5%\n",
      "Test accuracy: 89.8%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 1001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 50 == 0):\n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "4_convolutions.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
